{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba450fb1-8a26-4894-ab7a-5d7bfefe90ce",
      "metadata": {},
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary 代码 for 这个 <一个 href=\"http://mng.bz/orYv\">构建 一个 大语言模型 From Scratch</一个> book by <一个 href=\"https://sebastianraschka.com\">Sebastian Raschka</一个><br>\n",
        "<br>代码 repository: <一个 href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</一个>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<一个 href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></一个>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c9672d-8d0c-470d-ac2d-1271f8ec3f14",
      "metadata": {},
      "source": [
        "# 第 6 练习 解答"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fea8be3-30a1-4623-a6d7-b095c6c1092e",
      "metadata": {},
      "source": [
        "## 练习 6.1: Increasing 这个 context length"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5860ba9f-2db3-4480-b96b-4be1c68981eb",
      "metadata": {},
      "source": [
        "我们 can pad 这个 inputs to 这个 maximum number of tokens 这个 模型 supports by setting 这个 max length to 1024:\n",
        "\n",
        "```python\n",
        "max_length = 1024\n",
        "\n",
        "train_dataset = SpamDataset(base_path / \"train.csv\", max_length=max_length, 分词器=分词器)\n",
        "val_dataset = SpamDataset(base_path / \"验证.csv\", max_length=max_length, 分词器=分词器)\n",
        "test_dataset = SpamDataset(base_path / \"测试.csv\", max_length=max_length, 分词器=分词器)\n",
        "```\n",
        "\n",
        "或者, equivalently, 我们 can 定义 这个 `max_length` via:\n",
        "\n",
        "```python\n",
        "max_length = 模型.pos_emb.权重.shape[0]\n",
        "```\n",
        "\n",
        "或者",
        "\n",
        "```python\n",
        "max_length = BASE_CONFIG[\"context_length\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0f4d5d-17fd-4265-93d8-ea08a22fdaf8",
      "metadata": {},
      "source": [
        "For convenience, 你 can 运行 这个 experiment via\n",
        "\n",
        "```bash\n",
        "python additional-experiments.py --context_length \"model_context_length\"\n",
        "```\n",
        "\n",
        "using 这个 代码 in 这个 [../02_bonus_additional-experiments](../02_bonus_additional-experiments) folder, 哪个 results in 一个 substantially worse 测试 准确率 of 78.33% (versus 这个 95.67% in 这个 main 第)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a780455-f52a-48d1-ab82-6afd40bcad8b",
      "metadata": {},
      "source": [
        "## 练习 6.2: Finetuning 这个 whole 模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56aa5208-aa29-4165-a0ec-7480754e2a18",
      "metadata": {},
      "source": [
        "Instead of finetuning just 这个 final Transformer block, 我们 can finetune 这个 entire 模型 by removing 这个 following lines from 这个 代码:\n",
        "\n",
        "```python\n",
        "for param in 模型.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "\n",
        "For convenience, 你 can 运行 这个 experiment via\n",
        "\n",
        "```bash\n",
        "python additional-experiments.py --trainable_layers all\n",
        "```\n",
        "\n",
        "using 这个 代码 in 这个 [../02_bonus_additional-experiments](../02_bonus_additional-experiments) folder, 哪个 results in 一个 1% improved 测试 准确率 of 96.67% (versus 这个 95.67% in 这个 main 第)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2269bce3-f2b5-4a76-a692-5977c75a57b6",
      "metadata": {},
      "source": [
        "## 练习 6.3: Finetuning 这个 首先 versus last 词元 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7418a629-51b6-4aa2-83b7-bc0261bc370f",
      "metadata": {},
      "source": [
        "Rather than finetuning 这个 last 输出 词元, 我们 can finetune 这个 首先 输出 词元 by changing \n",
        "\n",
        "```python\n",
        "模型(input_batch)[:, -1, :]\n",
        "```\n",
        "\n",
        "to\n",
        "\n",
        "```python\n",
        "模型(input_batch)[:, 0, :]\n",
        "```\n",
        "\n",
        "everywhere in 这个 代码.\n",
        "\n",
        "For convenience, 你 can 运行 这个 experiment via\n",
        "\n",
        "```\n",
        "python additional-experiments.py --trainable_token 首先\n",
        "```\n",
        "\n",
        "using 这个 代码 in 这个 [../02_bonus_additional-experiments](../02_bonus_additional-experiments) folder, 哪个 results in 一个 substantially worse 测试 准确率 of 75.00% (versus 这个 95.67% in 这个 main 第)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}